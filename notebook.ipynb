{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Enhanced localization in 5G networks    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca14aac991422a61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec5ef52fff4ccfa6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81e2febc8be8208c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataframe\n",
    "\n",
    "# load the coverage and cir datasets\n",
    "n_datapoints = 100000\n",
    "df = load_dataframe(f'data/5G_cov_cir_C1_interpolated_{n_datapoints}.csv')\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4e2e36faf4d58d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data splitting\n",
    "The dataset is split between a training set and a testing set.\n",
    "We use 80% of the data for training the models and the remaining 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6291ddb929da667a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Y = df[['latitude', 'longitude']]\n",
    "\n",
    "X = df.drop(['latitude', 'longitude'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e990fddda10b9f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model building"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd0f5466630e026"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression\n",
    "\n",
    "I'm using Linear regression, since that is the simplest ML algorithm and is a low hanging fruit to test.\n",
    "The potential issue with using this is that it assumes a linear relationship between input and output.\n",
    "I'm yet not sure if that is the case for the signal data, but it poses a potential challenge."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b25530f2461ae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c548ba03fd42fd49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "605502429787447d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying model for prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8775ba35c2276723"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_lr_train_pred = lr.predict(X_train)\n",
    "y_lr_test_pred = lr.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c0d9d96b861f924",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abbb46a1965b8794"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import mean_position_error\n",
    "# training data performance\n",
    "\n",
    "lr_train_mpe = mean_position_error(y_train, y_lr_train_pred)\n",
    "lr_test_mpe = mean_position_error(y_test, y_lr_test_pred)\n",
    "errors_lr = pd.DataFrame([[\"Linear Regression\", lr_train_mpe, lr_test_mpe]], columns=['Model', 'Train MPE', 'Test MPE'])\n",
    "\n",
    "print(\"Performance evaluation: Linear Regression\")\n",
    "print(\"Training Mpe:\", lr_train_mpe)\n",
    "print(\"Test Mpe:\", lr_test_mpe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe621999fb92ddf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-NN\n",
    "The KNN algorithm is different from Linear Regression in the way that it remembers the dataset instead of learning a model.\n",
    "It will try to find the n closest neighbours and predict the label based on them.\n",
    "This has more options in terms of parameters we can adjust so we run a grid search in order to determine the best parameters.\n",
    "But is the dataset suited for this kind of model? Idk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c6a0afc0441305d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58569666938d771f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sample hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the KNN regressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Grid search for the best parameters\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)  # cv is the number of folds for cross-validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best model:\", best_knn_model)\n",
    "\n",
    "# fit the model\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "knn = best_knn_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8108354194cf5f86",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying the model for prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c04db9bd2d2bb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_knn_train_pred = knn.predict(X_train)\n",
    "\n",
    "y_knn_test_pred = knn.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df82486babfee2b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance evaulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2c9f85df4ecdeb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import mean_position_error\n",
    "knn_train_mpe = mean_position_error(y_train, y_knn_train_pred)\n",
    "knn_test_mpe = mean_position_error(y_test, y_knn_test_pred)\n",
    "errors_knn = pd.DataFrame([[\"KNN\",knn_train_mpe, knn_test_mpe]], columns= ['Model','Train MPE', 'Test MPE'])\n",
    "\n",
    "print(\"Performance evaluation: KNN\")\n",
    "print(\"Training Mpe:\", knn_train_mpe)\n",
    "print(\"Test Mpe:\", knn_test_mpe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d487bb59ffc8d41",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest\n",
    "Uses a desicion tree strategy for regression. Should be scalable for larger datasets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3236694cb3334c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "508936fe2c5df0fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define your model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt']  # Number of features to consider at every split\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best model:\", best_rf)\n",
    "\n",
    "# Use the best estimator for further predictions\n",
    "rf = best_rf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b8b25b22c1840d7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying the model for prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88c550944c7b18af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_rf_train_pred = rf.predict(X_train)\n",
    "y_rf_test_pred = rf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdab97684c38bf6f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance evalutaion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72d3d184e0585a49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rf_train_mpe = mean_position_error(y_train, y_rf_train_pred)\n",
    "rf_test_mpe = mean_position_error(y_test, y_rf_test_pred)\n",
    "errors_rf = pd.DataFrame([[\"Random Forest\",rf_train_mpe, rf_test_mpe]], columns= ['Model','Train MPE', 'Test MPE'])\n",
    "\n",
    "print(\"Performance evaluation: Random Forest\")\n",
    "print(\"Training Mpe:\", rf_train_mpe)\n",
    "print(\"Test Mpe:\",rf_test_mpe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "842d4d682e29f8c7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GradientBoostRegressor\n",
    "Uses many weak learners to build a strong prediction model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1163b26eef2d3461"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d92195c2b949cec0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Define the model\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr = MultiOutputRegressor(gbr)\n",
    "# Fit the model\n",
    "gbr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51ab554d85bd4f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying the model for predictioin"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0eb3f4200d21820"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_gbr_train_pred = gbr.predict(X_train)\n",
    "y_gbr_test_pred = gbr.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f79d8614adaf54be",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3775beecd6f7eccc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gbr_train_mpe = mean_position_error(y_train, y_gbr_train_pred)\n",
    "gbr_test_mpe = mean_position_error(y_test, y_gbr_test_pred)\n",
    "errors_gbr = pd.DataFrame([[\"Gradient Boost\",gbr_train_mpe, gbr_test_mpe]], columns= ['Model','Train MPE', 'Test MPE'])\n",
    "\n",
    "print(\"Performance evaluation: Gradient Boost\")\n",
    "print(\"Training Mpe:\", gbr_train_mpe)\n",
    "print(\"Test Mpe:\",gbr_test_mpe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba697dca698bee3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model comparison"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "646d99927dfd6395"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "errors_comp = pd.concat([errors_lr, errors_knn, errors_rf, errors_gbr], axis=0)\n",
    "\n",
    "print(errors_comp)\n",
    "\n",
    "# Assuming errors_comp is already prepared\n",
    "errors_comp_melted = errors_comp.melt(id_vars='Model', var_name='DataSet', value_name='MPE')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = sns.barplot(data=errors_comp_melted, x='Model', y='MPE', hue='DataSet', palette='viridis', width=0.7 )\n",
    "\n",
    "plt.title(f'Mean Positional Error (MPE), {n_datapoints} datapoints')\n",
    "plt.ylabel('Mean Positional Error (MPE)')\n",
    "plt.xlabel('ML Model')\n",
    "plt.yscale('log')  # Using a logarithmic scale to better visualize low values\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.3fm', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e22cbac06366c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes\n",
    "\n",
    "### Model selection\n",
    "Pros and cons of each model. How can they be applied and trained efficiently.\n",
    "\n",
    "### Parameter selection\n",
    "What parameters give the best results and why?\n",
    "\n",
    "### Dataset\n",
    "When do we run into problems with overfitting the model?\n",
    "And for what number of entries do we get the most accurate models?\n",
    "\n",
    "### Testing\n",
    "How should the models be tested and how can we confirm that the data is \n",
    "'valid' for testing accuracy.\n",
    "\n",
    "### Visulization\n",
    "Is there any good alternatives for visualizing the MPE for different models and sizes of \n",
    "the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c74546e7a1af0fe3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "466db0e679dd182c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
